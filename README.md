
---

# ğŸ¶ Lofi MIDI Generator with LSTM Neural Network

This project is a deep learning-based **music generation app** that takes a MIDI file as input, learns its note/chord sequences, and generates new lofi-style piano music. Built with **Keras, and music21**, it demonstrates how sequence modeling using LSTMs can create coherent musical compositions.

## ğŸ§  How It Works

1. **MIDI Parsing**: Extracts notes and chords from an uploaded MIDI file using `music21`.
2. **Sequence Preparation**: Converts notes into integer sequences to train on musical patterns.
3. **Model Architecture**:

   * 3 stacked LSTM layers (512 units each)
   * Dropout + Batch Normalization for regularization
   * Dense layers to predict the next note
4. **Music Generation**: Picks a random sequence and generates \~200 new notes.
5. **Output**: The generated sequence is saved as a downloadable `.mid` file.

---

## ğŸš€ Features

* Upload any MIDI file as input
* Generates new piano-based MIDI music
* Streamlit UI for easy web interaction
* Pre-trained model included (`final_weights.hdf5`)
* One-click download for the generated music

---

## ğŸ› ï¸ Tech Stack

* Python
* [Keras](https://keras.io/) (LSTM-based RNN)
* [music21](https://web.mit.edu/music21/) (for MIDI parsing/composition)
* Pickle (for note serialization)

---

## ğŸ§ª Try It Out

To run locally:

```bash
git clone https://github.com/yourusername/lofi-midi-generator.git
cd lofi-midi-generator
pip install -r requirements.txt
streamlit run app.py
```

Upload a `.mid` file and wait for your custom-generated lofi piece!

---

## ğŸ“ Sample Output

* Example input: a simple piano MIDI piece
* Generated output: [`lofi_output4.mid`](./lofi_output4.mid)

---

## ğŸ“ File Structure

```bash
.
â”œâ”€â”€ final_weights.hdf5        # Pre-trained LSTM model weights
â”œâ”€â”€ app.py                    # Main Streamlit app script
â”œâ”€â”€ lofi_output4.mid          # Sample generated output
â”œâ”€â”€ notes                     # Pickled list of parsed notes
â”œâ”€â”€ requirements.txt          # Required packages
â””â”€â”€ README.md                 # This file
```

---

## ğŸ“Œ Notes

* The model works best on piano MIDI files with clear melodies.
* `notes` file is overwritten on each run.
* Extendable to other instruments or genres with retraining.

---

## ğŸ§  Future Improvements

* Add melody conditioning (e.g., style transfer from specific genres)
* Fine-tune generation length and structure
* Add real-time MIDI playback in browser
* Dockerize for portable deployment

---

## ğŸ¤– Author

Built by a deep learning enthusiast exploring generative art and AI + music fusion.


---

## ğŸ“œ License

MIT License. See `LICENSE` for more details.

---


